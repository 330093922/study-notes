- [1 影响线程并发性的因素](#1-影响线程并发性的因素)
  - [1.1 上下文切换](#11-上下文切换)
  - [1.2 死锁](#12-死锁)
  - [1.3 资源限制](#13-资源限制)
- [2 并发机制的底层实现原理](#2-并发机制的底层实现原理)
  - [2.1 volatile](#21-volatile)
  - [2.2 synchronized](#22-synchronized)
  - [2.3 原子操作](#23-原子操作)



# java并发编程笔记

## 1 影响线程并发性的因素

### 1.1 上下文切换

**1. 概念**

CPU在执行A任务后且在切换到B任务前，会保存A任务的状态，以便下次切回A任务时可以加载到这个任务的状态，这个从保存到再加载的过程就是上下文切换。

**2. 测试工具**

- Lmbench3 可以测量上下文切换的时长（工具）
- vmstat 可以测量上下文切换的次数（linux 命令）

**3. 优化方案**

减少上下文切换的优化方案：

- 无锁并发编程（如将数据的ID按照Hash算法取模分段，不同线程处理不同段的数据）
- CAS 算法（Atomic包使用CAS算法更新数据，无需加锁）
- 使用最少线程，避免创建不需要的线程
- 使用协程：单线程里实现多任务的调度，并再单线程里维持多个任务间的切换

### 1.2 死锁

**1. 概念**

两个或两个以上的线程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种循环阻塞的现象。

**2. 优化方案**

避免死锁的方式：

- 避免一个线程同时获取多个锁
- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源
- 使用定时锁时，用 lock.tryLock(timeout)来替代使用内部锁机制
- 数据库锁的加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况

### 1.3 资源限制

**1. 概念**

程序的执行速度受限于计算机硬件资源或软件资源。

**2. 优化方案**

- 硬件资源限制：搭建服务器集群或使用ODPS、Hadoop，不同机器处理不同数据
- 软件资源限制：使用资源池将资源复用

## 2 并发机制的底层实现原理

### 2.1 volatile

**1. 概念**

Java 线程内存模型将确保所有线程看到 volatile 修饰的变量的值是一致的。

**2. 底层实现原理**

- 被 volatile 修饰的共享变量进行写操作时汇编代码中会额外增加 lock 前缀指令。
- lock 前缀指令在多处理器下的作用：
  - ①将当前处理器缓存行的数据写回到系统内存
  - ②此写回内存操作会使其他CPU里缓存的该内存地址数据失效（缓存一致性协议）

> 缓存一致性协议：每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是否过期，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里

**3. 优化方案**

- 追加到64字节优化队列出队和入队的性能

> 不能使用此方案的两个场景：
>
> ①缓存行非64字节宽的处理器下
>
> ②共享变量不会被频繁地写

### 2.2 synchronized

**1. 表现形式**

- 对普通同步方法：锁是当前实例对象
- 对静态同步方法：锁是当前类的Class对象
- 对同步方法块：锁是Synchronized括号里配置的对象

**2. synchronized底层实现原理**

JVM 中的实现原理：

进入和退出 monitor 对象来实现方法同步和代码块同步。

- 代码块同步：使用 monitorenter 和 monitorexit 指令实现
- 方法同步：**（实现细节待补充）**但同样可用代码块同步指令来实现

> 代码编译后，monitorenter 指令插入到同步代码块的开始位置，monitorexit 插入到方法结束处和异常处，JVM 保证每个 monitorenter 都有对应的 monitorexit 与之配对。
>
> 每个对象关联一个 monitor，monitor被持有表示对象处于锁定状态。所以线程执行到 monitorenter 指令时会尝试获得对象对应的 monitor 的所有权，即尝试获得对象锁。

#### 2.2.1 Java对象头

**1. 结构**

对象头长度：

- 数组类型：3字宽（word）
- 非数组类型：2字宽

> 1字宽在32位系统中为4字节，在64位系统中为8字节。

| 长度     | 内容                   | 说明                           |
| -------- | ---------------------- | ------------------------------ |
| 32/64bit | Mark Word              | 存储对象的 HashCode 或锁信息等 |
| 32/64bit | Class Metadata Address | 存储对象类型数据的指针         |
| 32/64bit | Array length           | 数组的长度（对象是数组时）     |

**2. Mark Word**

1）存储结构：

- 对象的 HashCode
- 分代年龄
- 锁标记位

Mark Word 在32位系统下，默认存储结构如下表：

| 锁状态   | 25bit           | 4bit         | 1bit 是否为偏向锁 | 2bit 锁标志位 |
| -------- | --------------- | ------------ | ----------------- | ------------- |
| 无锁状态 | 对象的 HashCode | 对象分代年龄 | 0                 | 01            |

Mark Word 在64位系统下，默认存储结构如下表：

| 锁状态 | 25bit             | 31bit         | 1bit     | 4bit     | 1bit         | 2bit     |
| ------ | ----------------- | ------------- | -------- | -------- | ------------ | -------- |
| 描述   |                   |               | cms_free | 分代年龄 | 是否为偏向锁 | 锁标志位 |
| 无锁   | unused            | HashCode      |          |          | 0            | 01       |
| 偏向锁 | ThreadID（54bit） | Epoch（2bit） |          |          | 1            | 01       |

2）状态变化

Mark Word 可变化为存储以下4种数据：

| 锁状态   | 29bit                                            | 1bit 是否为偏向锁 | 2bit 锁标志位 |
| -------- | ------------------------------------------------ | ----------------- | ------------- |
| 轻量级锁 | 指向栈中锁记录的指针（30bit）                    |                   | 00            |
| 重量级锁 | 指向互斥量（重量级锁）的指针（30bit）            |                   | 10            |
| GC 标记  | 空（30bit）                                      |                   | 11            |
| 偏向锁   | 线程ID（23bit）、Epoch（2bit）、分代年龄（4bit） | 1                 | 01            |

#### 2.2.2 锁的升级与对比

JDK 1.6 后锁有4种状态：

**无锁状态 → 偏向锁状态 → 轻量级锁状态 → 重量级锁状态**

**锁只能升级不能降级，目的时提高获得锁和释放锁的效率。**

**1. 偏向锁**

1）流程

![1588077092489](assets/1588077092489.png)

线程1表示偏向锁的初始化流程，线程2表示偏向锁撤销流程。

2）偏向锁初始化

①检查对象头：线程访问同步代码块时，检查对象头的 Mark Word 中是否存储了当前线程的偏向锁，是则初始化锁

②检查偏向锁标识：否则检查 Mark Word 中的偏向锁标识是否为1，即是否表示当前为偏向锁，是则初始化锁

③CAS：否则使用 CAS 竞争替换 Mark Word

> 线程访问同步代码块成功时，会使对象头和栈帧中的所记录里存储偏向锁指向当前线程 ID，以后再次进入时则无需 CAS 来加锁和解锁。

3）偏向锁的撤销

**前置条件：其他线程竞争偏向锁时，持有偏向锁的线程才会释放锁。**

①暂停线程：等待全局安全点（此刻无正在执行的字节码）暂停持有偏向锁的线程

②检查并解锁线：程检查此线程是否存活，不存活则将对象头设置为无锁状态；存活则解锁，将线程 ID 设为空

③恢复线程：恢复暂停的线程

**2. 轻量级锁**

1）流程

![1588212978365](assets/1588212978365.png)

自旋会消耗 CPU，为避免无用的自旋（如获得锁的线程被阻塞）升级为重量级锁。

> 重量级锁状态下，其他线程试图获取锁时会被阻塞，等持有锁的线程释放锁后会唤醒这些线程。

2）轻量级加锁

①创建并复制：线程访问同步代码块时，JVM 在当前线程的栈帧中创建存储锁记录的空间，复制 Mark Word：复制对象头中的 Mark Word 到锁记录中（Displaced Mark Word）

②CAS：线程使用 CAS 将对象头中的 Mark Word 替换为指向锁记录的指针，成功则加锁

③自旋：失败则使用自旋来获取锁

3）轻量级锁解锁

①使用原子的 CAS 操作将 Displaced Mark Word 替换回对象头，成功则解锁

②失败则膨胀成重量级锁

**3. JVM 参数**

- `-XX:BiasedLokcingStartupDelay=0` 关闭启动偏向锁时的延迟激活时间
- `-XX:-UseBiasedLocking=false` 关闭偏向锁，程序默认进入轻量级锁状态

**4. 锁对比**

| 锁       | 优点                                                         | 缺点                                           | 适用场景                             |
| -------- | ------------------------------------------------------------ | ---------------------------------------------- | ------------------------------------ |
| 偏向锁   | 加锁和解锁无需额外消耗，和执行非同步方法相比仅存在纳秒级差距 | 若线程间存在锁竞争，则会带来额外的锁撤销的消耗 | 只有一个线程访问同步块的场景         |
| 轻量级锁 | 竞争的线程不会阻塞，提高程序的响应速度                       | 若始终得不到锁竞争的线程，使用自旋会消耗 CPU   | 追求响应时间。同步块执行速度个非常快 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗 CPU                             | 线程阻塞，响应时间缓慢                         | 追求吞吐量，同步块执行时间较长       |

### 2.3 原子操作

**1. 概念**

不可被中断的一个或一系列操作。

**2. 术语**

- 缓存行（Cache line）：缓存的最小操作单位

- 比较并交换（CAS，Compare and Swap）：操作时需要输入一个旧值（操作前的期望值）和一个新值，操作前先比较旧值是否变化，无变化则替换成新值；有变化则不交换

- CPU 流水线（CPU pipeline）：CPU 中5 ~ 6个不同功能的电路单元组成一条流水线，将一条 X86 指令分成5 ~ 6步后再由这些电路分别执行，实现在一个 CPU 时钟周期完成一条指令，以此来提高 CPU 运算速度

- 内存顺序冲突（Memory order violation）：通常由假共享引起，假共享是指多个 CPU 同时修改一同一个缓存行的不同部分而引起其中一个 CPU 的操作无效

  > 出现内存顺序冲突时，CPU 必须清空流水线。

#### 2.3.1 处理器实现原子操作

**1. 实现方式**

32位 IA-32 处理器：

> 处理器会自动保证基本的内存操作的原子性，因为处理器读取一个字节时，其他处理器则不能访问这个字节的内存地址。
>
> 无法保证原子性的操作，如跨总线宽度、跨多个缓存行和跨页表的访问。

**2. 实现原理**

1）总线锁定机制

处理器提供一个 LOCK# 信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞，此时当前处理器可以独占共享内存。

> i++ 问题：经典的读改写操作，即多个处理器同时对共享变量进行读改写操作，操作完导致共享变量的值与期望不一致，如两个处理器同时读到 i 的值为1，然后同时处理 i = i  + 1，期望结果是3，结果处理完是2。

2）缓存锁定机制

内存区域如果被缓存在处理器的缓存行中，且在 Lock 操作期间被锁定，当它执行锁操作回写到内存时，处理器不在总线上声明 LOCK# 信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性

> 频繁使用的内存会缓存在处理器的 L1、L2 和 L3 高速缓存里。
>
> 缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行数据时，会使缓存行无效。

**3. 特殊场景**

不使用缓存锁定，而使用总线锁定的场景：

- 操作数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时
- 处理器不支持缓存锁定情况（如 Intel 486 和 Pentium 处理器）

**4. 实现 Lock 前缀的指令**

这些指令操作的内存区域会加锁，其他处理器无法同时访问：

- 位测试和修改指令：BTS、BTR、BTC
- 交换指令：XADD、CMPXCHG
- 操作数和逻辑指令：ADD、OR

#### 2.3.2 Java实现原子操作

**1. 实现方式**

- 循环 CAS
- 锁机制

**2. 循环 CAS**

1）实现原理

JVM 中的 CAS 底层是利用处理器的 CMPXCHG指令实现的，原理是循环进行 CAS 操作直到成功为止。

2）CAS 三大问题

- ABA 问题（  一个值A变为B后再变为A，CAS 检查此操作值时，视为无变化）
- 循环时间长开销大（长时间的自旋 CAS 不成功会消耗大量 CPU 资源）
- 只能保证一个共享变量的原子操作（多个共享变量无法同时循环 CAS）

3）问题解决方案

①ABA问题：

加版本号。

> JDK1.5 后 Atomic 包中提供 AtomicStampedReference 类来解决 ABA 问题，此类的 compareAndSet 方法会同时检查新旧引用和预期标志值，全部相等则更新。

②循环时间长开销大：

pause指令。

> pause 指令作用：①延迟流水线执行指令（de-pipeline）使 CPU 不回消耗过多的执行资源；②避免再退出循环时因内存顺序冲突而引起 CPU 流水线被清空（CPU pipeline Flush），提高 CPU 的执行效率。

③只能保证一个共享变量的原子操作：

- 多个共享变量合并为一个共享变量来操作

> JDK1.5 后提供了 AtomicReference 类，多个共享变量可放入一个对象里来 CAS。

- 锁

> 只有获得锁的线程才能操作锁定的内存区域。
>
> **除了偏向锁**，JVM 实现锁的方式都采用了循环 CAS（进入同步块时 CAS 获得锁，退出时 CAS 释放锁）。

**3. 锁机制**

见章节 2.2.2 锁的升级与对比。

## 3 Java内存模型

### 3.1 Java内存模型基础

#### 3.1.1 并发模型的两个关键问题

**1. 问题**

- 线程间的通信（线程之间交换信息的机制）
- 线程间的同步（控制不同线程间操作发生相对顺序的机制）

**2. 解决方案**

1）共享内存

线程之间共享程序的公共状态，通过写-读内存中的公共状态进行

- 隐式通信
- 显式同步

2）消息传递

线程之间没有公共状态，通过发送消息进行

- 显式通信
- 隐式同步（因为消息的发送必须再消息的接收之前）

#### 3.1.2 Java内存模型的抽象结构

**1. 概念**

Java 内存模型（JMM）定义了线程和主内存之间的抽象关系。

**2. 结构**

- 主内存：存储线程之间的共享变量
- 线程私有内存（抽象概念，非真实存在）：存储该线程读/写共享变量的副本

> 线程私有内存涵盖了缓存、写缓冲区、寄存器、其他硬件和编译器优化。

**3. 作用对象**

堆内存中的：

- 实例域
- 静态域
- 数组元素

> 局部变量、方法定义参数和异常处理器参数不会在线程之间共享。

**4. 作用**

决定一个线程对共享变量的写入结果，何时对另一个线程可见。